{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f387bc3e",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorium: Regresja wielowymiarowa — Wariant 10\n",
    "**Temat:** Analiza zapotrzebowania na pracowników w firmach (wariant 10)  \n",
    "**Cel:** Zbudować i ocenić modele sieci neuronowych przewidujące:  \n",
    "- liczbę wymaganych pracowników  \n",
    "- średnie wynagrodzenie  \n",
    "\n",
    "Notebook zawiera: generację danych, preprocessing, porównanie 3 architektur sieci, wykresy i sprawozdanie.\n",
    "\n",
    "> Dane treningowe (wg. instrukcji):  \n",
    "> - cechy wejściowe: liczba projektów, średni czas trwania projektu (miesiące), budżet firmy  \n",
    "> - wyjścia (target): liczba wymaganych pracowników, średnie wynagrodzenie  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importy i ustawienia\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# deterministyczność (tam gdzie to możliwe)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f25b9",
   "metadata": {},
   "source": [
    "## Generacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cdfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generacja danych zgodnie z Listing 13 (przeskalowane zgodnie z instrukcją)\n",
    "N = 5000  # liczba próbek\n",
    "\n",
    "# X: liczba projektów, średni czas trwania projektu (miesiące), budżet firmy\n",
    "X = np.random.rand(N, 3) * np.array([50, 24, 10_000_000.0])\n",
    "\n",
    "# y: liczba wymaganych pracowników, średnie wynagrodzenie\n",
    "y = np.random.rand(N, 2) * np.array([500.0, 10_000.0])\n",
    "\n",
    "# Uporządkowanie do DataFrame (dla czytelności)\n",
    "df = pd.DataFrame(np.hstack([X, y]), columns=[\n",
    "    'n_projects', 'avg_duration_months', 'budget',\n",
    "    'req_employees', 'avg_salary'\n",
    "])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4459bc",
   "metadata": {},
   "source": [
    "## Preprocessing (skalowanie, podział na zbiory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Podział na zbiór treningowy i testowy oraz skalowanie cech\n",
    "X = df[['n_projects', 'avg_duration_months', 'budget']].values\n",
    "y = df[['req_employees', 'avg_salary']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standaryzacja cech wejściowych (skalowanie budżetu ma duże wartości)\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Standaryzacja targetów ułatwi trenowanie; zapiszemy skalery, aby odwrócić transformację\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d65fe",
   "metadata": {},
   "source": [
    "## Definicja architektur i funkcji pomocniczych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funkcja pomocnicza do budowania modeli o różnych architekturach\n",
    "def build_model(architecture='1hidden', input_shape=(3,)):\n",
    "    model = keras.Sequential()\n",
    "    if architecture == '1hidden':\n",
    "        model.add(layers.Input(shape=input_shape))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "    elif architecture == '2hidden':\n",
    "        model.add(layers.Input(shape=input_shape))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    elif architecture == '3hidden':\n",
    "        model.add(layers.Input(shape=input_shape))\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "    else:\n",
    "        raise ValueError('Unknown architecture')\n",
    "    model.add(layers.Dense(2))  # 2 wartości wyjściowe (regresja wielowymiarowa)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004779a",
   "metadata": {},
   "source": [
    "## Trening modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parametry treningu\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "architectures = ['1hidden', '2hidden', '3hidden']\n",
    "histories = {}\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "for arch in architectures:\n",
    "    print('\\n--- Trening modelu:', arch, '---')\n",
    "    model = build_model(arch, input_shape=(X_train_scaled.shape[1],))\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train_scaled,\n",
    "        validation_split=0.15,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "    models[arch] = model\n",
    "    histories[arch] = history\n",
    "    # ewaluacja na zestawie testowym (odwracamy skalowanie predykcji)\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    results[arch] = {'mse': mse, 'mae': mae}\n",
    "    print(f'Arch: {arch} -> MSE: {mse:.4f}, MAE: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9153c",
   "metadata": {},
   "source": [
    "## Wyniki i wykresy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699da10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wykresy: historia MSE (loss) dla każdej architektury\n",
    "for arch in architectures:\n",
    "    h = histories[arch]\n",
    "    plt.figure()\n",
    "    plt.plot(h.history['loss'], label='train_loss')\n",
    "    plt.plot(h.history['val_loss'], label='val_loss')\n",
    "    plt.title(f'Loss (MSE) - {arch}')\n",
    "    plt.xlabel('Epoka')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Scatter: rzeczywiste vs przewidywane (dla najlepszego modelu wg MSE)\n",
    "best_arch = min(results, key=lambda k: results[k]['mse'])\n",
    "print('\\nNajlepsza architektura wg MSE:', best_arch, results[best_arch])\n",
    "\n",
    "best_model = models[best_arch]\n",
    "y_pred_best = scaler_y.inverse_transform(best_model.predict(X_test_scaled))\n",
    "\n",
    "# Scatter dla obu wyjść w osobnych wykresach\n",
    "plt.figure()\n",
    "plt.scatter(y_test[:,0], y_pred_best[:,0], alpha=0.4)\n",
    "plt.title('Rzeczywista vs Przewidywana - liczba wymaganych pracowników')\n",
    "plt.xlabel('Rzeczywista liczba pracowników')\n",
    "plt.ylabel('Przewidywana liczba pracowników')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_test[:,1], y_pred_best[:,1], alpha=0.4)\n",
    "plt.title('Rzeczywista vs Przewidywana - średnie wynagrodzenie')\n",
    "plt.xlabel('Rzeczywista średnie wynagrodzenie')\n",
    "plt.ylabel('Przewidywane średnie wynagrodzenie')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365763af",
   "metadata": {},
   "source": [
    "## Tabela metryk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tabela wyników metryk dla modeli\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98413b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Sprawozdanie (podsumowanie eksperymentu)\n",
    "\n",
    "**Opis zadania:** Wariant 10 — prognozowanie zapotrzebowania na pracowników i średniego wynagrodzenia na podstawie\n",
    "liczby projektów, średniego czasu trwania projektu oraz budżetu firmy.\n",
    "\n",
    "**Przyjęte założenia:** Dane wygenerowano syntetycznie zgodnie z Listing 13 z instrukcji laboratorium. Dane wejściowe i wyjściowe\n",
    "zostały zeskalowane, a modele trenowano na znormalizowanych targetach (skalowanie odwrotne do oceny).\n",
    "\n",
    "**Architektury testowane:**  \n",
    "- `1hidden`: jedna warstwa ukryta 64 neurony  \n",
    "- `2hidden`: dwie warstwy ukryte (64 → 32)  \n",
    "- `3hidden`: trzy warstwy ukryte (128 → 64 → 32)\n",
    "\n",
    "**Metryki oceny:** MSE i MAE na zbiorze testowym.  \n",
    "\n",
    "**Wnioski:**  \n",
    "- Porównując MSE i wykresy rzeczywiste vs przewidywane można ocenić, która architektura lepiej approximuje zależności.  \n",
    "- Dla syntetycznych, losowo generowanych danych różnice mogą być niewielkie; w praktycznych zadaniach należy stosować regularizację, cross-validation oraz analizę wpływu cech (feature importance).\n",
    "\n",
    "**Możliwe rozszerzenia:**  \n",
    "- Zastosowanie K-Fold cross-validation, grid search (liczba warstw, liczba neuronów, learning rate).  \n",
    "- Generowanie danych bardziej realistycznych (np. zależność budżetu od liczby projektów, korelacje między targetami).  \n",
    "- Dodanie ograniczeń (np. wymagane pracownicy jako liczba całkowita — regresja z postprocessingiem do najbliższej liczby całkowitej).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
